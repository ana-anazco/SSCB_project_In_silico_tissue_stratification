{"cells":[{"cell_type":"markdown","metadata":{"id":"mvCXZo75WZFa"},"source":[]},{"cell_type":"markdown","metadata":{"id":"VP0mb8uCfYzV"},"source":["# instal and load required libraries\n","\n","The first step before starting to analyze the bulk RNA data is to install, and then load all the packges needed. To help us with that we will use BiocManager.  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1138481,"status":"ok","timestamp":1694551938751,"user":{"displayName":"Leonardo Mendes-Silva","userId":"04125321159063099921"},"user_tz":-60},"id":"tW95Ujh1ViIy","outputId":"709cd4f5-f63a-4250-fee9-6a4fd0af728f","vscode":{"languageId":"r"}},"outputs":[],"source":["# install required packages\n","if (!require(\"BiocManager\", quietly = TRUE))\n","    install.packages(\"BiocManager\")\n","BiocManager::install(\"GEOquery\") \n","BiocManager::install(\"Biobase\") \n","BiocManager::install(\"affy\")\n","BiocManager::install(\"oligo\")\n","BiocManager::install(\"biomaRt\")\n","# install not-BiocManager packages\n","install.packages('umap')\n","install.packages('tidyverse')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10349,"status":"ok","timestamp":1694552491958,"user":{"displayName":"Leonardo Mendes-Silva","userId":"04125321159063099921"},"user_tz":-60},"id":"wUQ0DoF5fh82","outputId":"1df8e629-1198-4736-f320-3e5b2cb41330","vscode":{"languageId":"r"}},"outputs":[],"source":["# load libraries\n","library(GEOquery)\n","library(Biobase)\n","library(affy)\n","library(oligo)\n","library(biomaRt)\n","library(tidyverse)"]},{"cell_type":"markdown","metadata":{"id":"CRuuMFrEfsrC"},"source":["## Import dataset\n","\n","The GEO dataset that we are going to use is GSE3790, from [Hodges et al 2006]([link](https://pubmed.ncbi.nlm.nih.gov/16467349/). In this study the authors used two platforms \"GPL96\" and \"GPL97\". For sake of time we will just consider \"GPL96\", and start from the code generated from NCBI geo2R. \n","The Bioconductor packged for this platform is \"Affyhgu133aExpr\", and goes with the label \"affy_hg_u133a_2\" in biomaRt.\n","For more detail, here is the GEO [link](https://www.ncbi.nlm.nih.gov/geo/geo2r/?acc=GSE3790&platform=GPL96) for the data set's platform. \n","Now we can get the data from this GEO obeject and began our analysis, which will be save in the `eset` object."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16778,"status":"ok","timestamp":1694517136791,"user":{"displayName":"Leonardo Mendes-Silva","userId":"04125321159063099921"},"user_tz":-60},"id":"H7T1UaagxQXa","outputId":"4e38880f-9ada-4023-d230-bbbb9196bb3a","vscode":{"languageId":"r"}},"outputs":[],"source":["# to ran annotation locally\n","## BiocManager::install(\"hgu133a2.db\")\n","## BiocManager::install(\"Affyhgu133aExpr\")\n","## library(Affyhgu133aExpr)\n","## library(hgu133a.db)\n","## library(hgu133a2.db)\n","\n","# Download and get the expression set\n","query_GEO <- \"GSE3790\"\n","gset <- getGEO(query_GEO, GSEMatrix =TRUE, AnnotGPL = TRUE) #, getGPL=TRUE)\n","if (length(gset) > 1) idx <- grep(\"GPL96\", attr(gset, \"names\")) else idx <- 1\n","eset <- gset[[idx]]\n","\n","# to ran annotation locally\n","# add affymetrix chip platform annotation to eset\n","# eset@annotation <- 'Affyhgu133aExpr'"]},{"cell_type":"markdown","metadata":{},"source":["Now before we continue, lets us define some variable to be use througout the analysis. One of this is the `sampling_check`, which is use to quicly define subsetting ranges to check tables as we go. The second is the `platform_array`, just to avoid typos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4310-HOGuSJ","vscode":{"languageId":"r"}},"outputs":[],"source":["# create parameter variables\n","## variable to subset array\n","sampling_check = c(1:5)\n","## array platform label\n","platform_array = 'affy_hg_u133a_2'"]},{"cell_type":"markdown","metadata":{},"source":["Now we can continue by matching the `probeNames` to the name of the genes. For that we used `biomaRt` package. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":750},"executionInfo":{"elapsed":1910,"status":"error","timestamp":1694516950767,"user":{"displayName":"Leonardo Mendes-Silva","userId":"04125321159063099921"},"user_tz":-60},"id":"OlrM7w8i4KfW","outputId":"85d263e5-bb61-40b3-bf67-da381b38e895","vscode":{"languageId":"r"}},"outputs":[],"source":["# Check probeNames\n","featureNames(eset)[sampling_check] # works\n","# oligo::probeNames(eset) # does not work\n","\n","## get gene annotation from biomaRt\n","mart <- useMart(\"ENSEMBL_MART_ENSEMBL\")\n","mart2 <- useDataset(\"hsapiens_gene_ensembl\", mart)\n","\n","# Create annotation loopk up object\n","## this is to match the probes name to their respective genes\n","annotLookup <- biomaRt::getBM(\n","  mart = mart2,\n","  attributes = c(\n","    platform_array,\n","    \"ensembl_gene_id\",\n","    \"hgnc_symbol\"\n","  ),\n","  filter= platform_array,\n","  values = rownames(exprs(eset)))\n","\n","# exprs(set) average\n","xprs <-  exprs(eset)\n","## add column with probe names\n","xprs <- cbind(row.names(xprs),xprs)\n","## rename the column with affy chip's name\n","colnames(xprs)[1] <- platform_array\n","dim(xprs)\n","## add a column with the name of the gene from the biomaRt table\n","## remove the columns with 'str' data, only keep the numerical\n","xprs_annot <- dplyr::left_join(as.data.frame(xprs),annotLookup, by= platform_array)[,1-2]\n","dim(xprs_annot)"]},{"cell_type":"markdown","metadata":{"id":"TbT3YvsAJx_D"},"source":["## Process data set\n","\n","### Create a dataframe with summarized probes\n","\n","Now we have too many probes for the less number of genes. To solve this, we looked to the boxplots in the GEO website, and we check that the data was already normalized. Therefore, for sake of time, we will just consider doing the `mean()` for all probes of each gene. Thus, we will loop through each gene (rows; features) and through each sample (cols; sample) and calculate the average of the values. The resulting dataframe will be the variable `xprs_processed`.\n","As control for this steps we will look at the dimension of the matrices, and we expect to end up with a less rows in the last data frame compared to the starting data frame---this is due to each gene corresponding to n-probes.\n","We should point out, that we are not interest in knowing the relative expression (healthy vs disease), because our main problem to solve is sample specific."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cphDreu2K937","vscode":{"languageId":"r"}},"outputs":[],"source":["# get the unique genes\n","repeated <- unique(xprs_annot[duplicated(xprs_annot$ensembl_gene_id),]$ensembl_gene_id)\n","\n","# Initialize xprs_avg as a list ####\n","xprs_avg <- list()\n","\n","# Make the average of different probes grouped by gene\n","## remove cols 202 and 203 that are strings\n","for (gene in repeated) {\n","  temp <- sapply(xprs_annot[xprs_annot$ensembl_gene_id == gene,-c(202,203)],  \n","                 function(x) {\n","                   mean(as.numeric(x), na.rm = TRUE)\n","                 })\n","  # Add temp to the list\n","  xprs_avg[[gene]] <- temp\n","}\n","\n","# Convert the list to a data frame\n","xprs_avg <- do.call(rbind, xprs_avg)\n","\n","# Convert matrix to data frame\n","xprs_avg <- as.data.frame(xprs_avg)\n","\n","# bring back removed columns with string (genes)\n","## Add row names as a new column\n","xprs_avg$ensembl_gene_id <- rownames(xprs_avg)\n","\n","# remove the duplicated from the original dataframe\n","xprs_unique <- xprs_annot[!xprs_annot$ensembl_gene_id %in% repeated,]\n","dim(xprs_unique)\n","\n","# check if they are split => expected 0 True values\n","unique(xprs_unique$ensembl_gene_id) == repeated\n","\n","# put ENSEMBL as the first column\n","xprs_avg <- xprs_avg[, c(\"ensembl_gene_id\", setdiff(names(xprs_avg), \"ensembl_gene_id\"))]\n","xprs_unique <- xprs_unique[, c(\"ensembl_gene_id\", setdiff(names(xprs_unique), \"ensembl_gene_id\"))][,-c(203)]\n","# create a new dataframe with averaged values with individual\n","xprs_processed <- rbind(xprs_avg,xprs_unique)"]},{"cell_type":"markdown","metadata":{},"source":["Now just for quality control, lets check the size of the resulting dataframes. If TRUE all is good. "]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# validate summarization\n","# the number of row names should be smaller\n","(length(repeated)+dim(xprs_unique)[1]) < dim(xprs) \n","## the number of rows should be equal to the amount of unique genes\n","sum(length(repeated),dim(xprs_unique)[1]) == (length(unique(xprs_annot$ensembl_gene_id)))\n","## check final table\n","dim(xprs_processed)[1] == (length(unique(xprs_annot$ensembl_gene_id)))"]},{"cell_type":"markdown","metadata":{},"source":["## Export dataset\n","\n","Now, the last touches. We need split the string in the annotation eset that contain the `age` and `condition` to match the matrix of training data from scRNA-seq. When this is done we can export as `.csv` to import into the other file where we are building the model."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# get annotation data from eset\n","anno <- pData(eset)\n","head(anno)"]},{"cell_type":"markdown","metadata":{},"source":["Now we need to check the name of the columns that contains the string to be parsed, and add it to the function `select()`. "]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# subset the anno table for the specific columns that needs to be parsed \n","anno2 <- select(anno,characteristics_ch1)\n","# Create new columns\n","anno2_split <- anno2 %>%\n","  mutate(condition = ifelse(str_detect(characteristics_ch1, \"control\"), \"control\", \"HD\"),\n","         condition_specified = str_extract(characteristics_ch1, \"(control|grade \\\\d)\"),\n","         age = as.numeric(str_extract(characteristics_ch1, \"(?<=Age = )\\\\d+\")),\n","         sex = str_extract(characteristics_ch1, \"(?<=sex = )[MF]\"))\n","anno2_split$source_name_ch1 <- anno$source_name_ch1 \n","anno2_split <-  select(anno2_split, -characteristics_ch1)\n","# Print the new data frame\n","print(anno2_split[sampling_check,])\n","row.names(anno2_split)[1]\n","row.names(anno2_split)[dim(anno2_split)[2]]\n","dim(anno2_split)\n","t_anno2_split <- as.data.frame(t(anno2_split))"]},{"cell_type":"markdown","metadata":{},"source":["Now that we have a dataframe with columns for each feature (age, condition ...) we need to merge it with the dataframe that has the mean values for each gene."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# add a new \"feature\" to match the same n-columns as in xprs_processed\n","t_anno2_split$ensembl_gene_id <- row.names(t_anno2_split)\n","t_anno2_split <- t_anno2_split[, c(\"ensembl_gene_id\", setdiff(names(t_anno2_split), \"ensembl_gene_id\"))]\n","dim(t_anno2_split)\n","# check if the colnames match\n","colnames(xprs_processed) == colnames(t_anno2_split)\n","# bind the rows of two data.frames\n","tissue_bulk_data <- rbind(xprs_processed,t_anno2_split)\n","dim(tissue_bulk_data)[1] == sum(dim(xprs_processed)[1] ,dim(t_anno2_split)[1] )"]},{"cell_type":"markdown","metadata":{},"source":["Finally, we have a dataframe ready to be exported and used to test the model with real data to which we want to know the % each cell type in the tissue.\n","See below parts of the final table."]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# print head\n","print(tissue_bulk_data[1:5,c(1,2,ncol(tissue_bulk_data))], row.names = FALSE)\n","# print tail\n","print(tissue_bulk_data[c((nrow(tissue_bulk_data)-5):nrow(tissue_bulk_data)),c(1,2,ncol(tissue_bulk_data))], row.names = FALSE)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# export to csv\n","write.csv(tissue_bulk_data, file= \"bulk_tissue_data.csv\", row.names = FALSE)\n","save.image(file = \"bulk_tissue_processed.Rdata\")"]},{"cell_type":"markdown","metadata":{},"source":["# session info"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["sessionInfo()"]}],"metadata":{"colab":{"collapsed_sections":["PfezCGb1XbR5"],"provenance":[]},"kernelspec":{"display_name":"R","name":"ir"},"language_info":{"name":"R"}},"nbformat":4,"nbformat_minor":0}
